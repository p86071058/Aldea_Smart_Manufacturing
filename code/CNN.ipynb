{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"},"colab":{"name":"CNN.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"wb8i7-4vGGKV"},"source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from sklearn.preprocessing import MinMaxScaler\n","import os"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZdnOM6uxGGKZ"},"source":["gpus = tf.config.experimental.list_physical_devices('GPU')\n","if gpus:\n","  try:\n","    # Currently, memory growth needs to be the same across GPUs\n","    for gpu in gpus:\n","      tf.config.experimental.set_memory_growth(gpu, True)\n","    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n","    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n","  except RuntimeError as e:\n","    # Memory growth must be set before GPUs have been initialized\n","    print(e)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HMCKuDZeGGKd"},"source":["path = '/home/motionlab/Desktop/weitai/project/smart_manufacturing/npy_file'\n","train = np.load(os.path.join(path, 'train_array.npy'))\n","train_log = np.load(os.path.join(path, 'train_log_array.npy'), allow_pickle = True)\n","# train_log = np.load(os.path.join(path, 'train_log_array.npy'), allow_pickle = False)\n","# test = np.load(os.path.join(path, 'test_array.npy'))\n","# test_log = np.load(os.path.join(path, 'test_log_array.npy'), allow_pickle = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rWRLqtc7GGKg"},"source":["def normalize_change(data):\n","    tensor = []\n","    for i in range(len(data)):\n","        data[i] = MinMaxScaler().fit_transform(data[i])\n","        data[i] = data[i].astype('float32')\n","        tensor.append(data[i])\n","    return data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aRMVkrfAGGKj"},"source":["def change_dtype(data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pibhho3EGGKm"},"source":["train = MinMaxScaler().fit_transform(train)\n","# test = MinMaxScaler().fit_transform(test)\n","train_features = normalize_change(train_log)\n","# test_features = normalize_change(test_log)\n","train_t = tf.convert_to_tensor(train_features)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8wEPVnV_GGKp"},"source":["train_features[0].dtype"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yh0KurbYGGKs"},"source":["train_log[0].dtype"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hLozy2Q0GGKv"},"source":["features.dtype"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"awvHWM2gGGKy"},"source":["target = np.load(os.path.join(path, 'target_array.npy'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KX19YyouGGK0"},"source":["target.dtype"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KXtc_c8VGGK2"},"source":["np.shape(train_log)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"af1CczREGGK4"},"source":["def custom_model():\n","    input_log = tf.keras.Input(shape = (None, 146))\n","    x = tf.keras.layers.Conv1D(8, kernel_size = 5, padding = 'same', activation = 'relu')(input_log)\n","    \n","    x = tf.keras.layers.MaxPool1D(pool_size = 5, padding = 'same')(x)\n","    \n","    x = tf.keras.layers.Conv1D(16, kernel_size = 5, padding = 'same', activation = 'relu')(x)\n","    \n","    x = tf.keras.layers.MaxPool1D(pool_size = 5, padding = 'same')(x)\n","    \n","    output = tf.keras.layers.Dense(4, activation = 'linear')(x)\n","    \n","    model = tf.keras.Model(input_log, output)\n","    \n","    model.compile(optimizer = tf.keras.optimizers.Adam(), loss = 'MAE', metrics = ['MeanAbsoluteError'])\n","    \n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4RRgqhOEGGK6"},"source":["custom_model().summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dpxAMIx1GGK9"},"source":["features = np.asarray(train_log)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0npLw9moGGLA"},"source":["features.dtype"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dT2B_IDOGGLD"},"source":["model = custom_model()\n","model.fit(features, target, epochs = 30, batch_size = 32, verbose = 2, shuffle = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1u-VcTOaGGLF"},"source":["train_features[0][0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kEFpJXzZGGLH"},"source":["np.shape(train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xXYOd7m6GGLJ"},"source":["np.shape(train_log[0])"],"execution_count":null,"outputs":[]}]}